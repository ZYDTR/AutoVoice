# çº§è”ç³»ç»Ÿå®ç°è®¡åˆ’ï¼šå…ˆ Diarization å†ç”¨ SenseVoice

## ä¸€ã€è°ƒç ”ç»“æœæ€»ç»“

### 1.1 Paraformer + Cam++ è¾“å‡ºæ ¼å¼ç¡®è®¤

ç»è¿‡å®é™…æµ‹è¯•ï¼Œç¡®è®¤äº† Paraformer + Cam++ çš„è¾“å‡ºç»“æ„ï¼š

```python
result = [
    {
        'key': 'æ–‡ä»¶å',
        'text': 'å®Œæ•´è½¬å½•æ–‡æœ¬',
        'timestamp': [[start_ms, end_ms], ...],  # æ—¶é—´æˆ³åˆ—è¡¨
        'sentence_info': [
            {
                'text': 'å¥å­æ–‡æœ¬',
                'start': 2990,      # å¥å­å¼€å§‹æ—¶é—´ï¼ˆæ¯«ç§’ï¼‰
                'end': 7990,        # å¥å­ç»“æŸæ—¶é—´ï¼ˆæ¯«ç§’ï¼‰
                'timestamp': [[2990, 3230], ...],  # å¥å­å†…çš„æ—¶é—´æˆ³
                'spk': 1            # è¯´è¯äºº IDï¼ˆæ•´æ•°ï¼‰
            },
            ...
        ]
    }
]
```

**å…³é”®å‘ç°ï¼š**
- âœ… `sentence_info` ä¸­åŒ…å«æ¯ä¸ªå¥å­çš„ `start`ã€`end` å’Œ `spk`ï¼ˆè¯´è¯äººIDï¼‰
- âœ… æ—¶é—´æˆ³å•ä½æ˜¯**æ¯«ç§’**
- âœ… è¯´è¯äººIDæ˜¯æ•´æ•°ï¼ˆå¦‚ 1, 2, 3...ï¼‰

### 1.2 SenseVoice è¾“å‡ºæ ¼å¼

SenseVoice çš„è¾“å‡ºæ ¼å¼ï¼ˆå·²çŸ¥ï¼‰ï¼š
```python
result = [
    {
        'text': 'è½¬å½•æ–‡æœ¬ï¼ˆåŒ…å«æƒ…æ„Ÿæ ‡ç­¾ï¼‰',
        # ä¸åŒ…å« timestamp å’Œ spk
    }
]
```

**å…³é”®ç‰¹æ€§ï¼š**
- âœ… åŒ…å«æƒ…æ„Ÿæ ‡ç­¾ï¼ˆå¦‚ `<|happy|>`ã€`<|music|>`ï¼‰
- âœ… è¯†åˆ«å‡†ç¡®ç‡é«˜
- âŒ ä¸æ”¯æŒ timestamp å’Œ speaker diarization

## äºŒã€å®ç°æ–¹æ¡ˆè®¾è®¡

### 2.1 æ ¸å¿ƒæ€è·¯

**"ç”¨ Paraformer å®šä½å®šäººï¼Œç”¨ SenseVoice ä¿®æ­£å†…å®¹"**

1. **ç¬¬ä¸€æ­¥ï¼ˆå®šä½ä¸å®šäººï¼‰**ï¼š
   - ä½¿ç”¨ Paraformer + Cam++ å¤„ç†å®Œæ•´éŸ³é¢‘
   - è·å–æ¯ä¸ªå¥å­çš„æ—¶é—´æˆ³ï¼ˆstart, endï¼‰å’Œè¯´è¯äººIDï¼ˆspkï¼‰
   - å¿½ç•¥ Paraformer çš„æ–‡æœ¬è¾“å‡ºï¼ˆå› ä¸ºè¦ç”¨ SenseVoice é‡æ–°è¯†åˆ«ï¼‰

2. **ç¬¬äºŒæ­¥ï¼ˆè¯†åˆ«å†…å®¹ï¼‰**ï¼š
   - æ ¹æ®æ—¶é—´æˆ³æå–éŸ³é¢‘ç‰‡æ®µ
   - ä½¿ç”¨ SenseVoice é‡æ–°è¯†åˆ«æ¯ä¸ªç‰‡æ®µ
   - è·å–å¸¦æƒ…æ„Ÿæ ‡ç­¾çš„æ–‡æœ¬

3. **ç¬¬ä¸‰æ­¥ï¼ˆåˆå¹¶ç»“æœï¼‰**ï¼š
   - å°†è¯´è¯äººIDï¼ˆæ¥è‡ªParaformerï¼‰ä¸æ–‡æœ¬ï¼ˆæ¥è‡ªSenseVoiceï¼‰åˆå¹¶
   - è¾“å‡ºæœ€ç»ˆç»“æœ

### 2.2 æŠ€æœ¯å®ç°è¦ç‚¹

#### 2.2.1 éŸ³é¢‘ç‰‡æ®µæå–

éœ€è¦ä½¿ç”¨éŸ³é¢‘å¤„ç†åº“æå–æŒ‡å®šæ—¶é—´æ®µçš„éŸ³é¢‘ï¼š

**æ–¹æ¡ˆAï¼šä½¿ç”¨ soundfile + numpyï¼ˆæ¨èï¼‰**
```python
import soundfile as sf
import numpy as np

def extract_audio_segment(audio_path, start_ms, end_ms):
    """
    æå–éŸ³é¢‘ç‰‡æ®µ
    
    Args:
        audio_path: éŸ³é¢‘æ–‡ä»¶è·¯å¾„
        start_ms: å¼€å§‹æ—¶é—´ï¼ˆæ¯«ç§’ï¼‰
        end_ms: ç»“æŸæ—¶é—´ï¼ˆæ¯«ç§’ï¼‰
    
    Returns:
        audio_data: éŸ³é¢‘æ•°æ®ï¼ˆnumpy arrayï¼‰
        sample_rate: é‡‡æ ·ç‡
    """
    # è¯»å–å®Œæ•´éŸ³é¢‘
    audio_data, sample_rate = sf.read(audio_path)
    
    # è½¬æ¢ä¸ºé‡‡æ ·ç‚¹ç´¢å¼•
    start_sample = int(start_ms * sample_rate / 1000)
    end_sample = int(end_ms * sample_rate / 1000)
    
    # æå–ç‰‡æ®µ
    segment = audio_data[start_sample:end_sample]
    
    return segment, sample_rate
```

**æ–¹æ¡ˆBï¼šä½¿ç”¨ pydubï¼ˆæ›´ç®€å•ï¼Œä½†éœ€è¦ ffmpegï¼‰**
```python
from pydub import AudioSegment

def extract_audio_segment_pydub(audio_path, start_ms, end_ms):
    """
    ä½¿ç”¨ pydub æå–éŸ³é¢‘ç‰‡æ®µ
    """
    audio = AudioSegment.from_file(audio_path)
    segment = audio[start_ms:end_ms]
    
    # è½¬æ¢ä¸º numpy arrayï¼ˆå¦‚æœéœ€è¦ï¼‰
    import numpy as np
    samples = np.array(segment.get_array_of_samples())
    if segment.channels == 2:
        samples = samples.reshape((-1, 2))
    
    return samples, segment.frame_rate
```

**æ¨èä½¿ç”¨æ–¹æ¡ˆAï¼ˆsoundfileï¼‰**ï¼Œå› ä¸ºï¼š
- âœ… ä¸éœ€è¦é¢å¤–ä¾èµ–ï¼ˆffmpegï¼‰
- âœ… æ€§èƒ½æ›´å¥½
- âœ… æ”¯æŒæ›´å¤šéŸ³é¢‘æ ¼å¼

#### 2.2.2 ä¸´æ—¶æ–‡ä»¶å¤„ç†

SenseVoice çš„ `generate` æ–¹æ³•éœ€è¦æ–‡ä»¶è·¯å¾„æˆ– numpy arrayã€‚å¦‚æœä¼ å…¥ numpy arrayï¼Œéœ€è¦ç¡®ä¿æ ¼å¼æ­£ç¡®ã€‚

**æ–¹æ¡ˆï¼šä½¿ç”¨ä¸´æ—¶æ–‡ä»¶æˆ–ç›´æ¥ä¼ å…¥ numpy array**
```python
import tempfile
import os

def process_segment_with_sensevoice(sense_model, audio_segment, sample_rate):
    """
    ä½¿ç”¨ SenseVoice å¤„ç†éŸ³é¢‘ç‰‡æ®µ
    
    æ–¹æ¡ˆ1ï¼šä¿å­˜ä¸ºä¸´æ—¶æ–‡ä»¶
    """
    with tempfile.NamedTemporaryFile(suffix='.wav', delete=False) as tmp_file:
        sf.write(tmp_file.name, audio_segment, sample_rate)
        result = sense_model.generate(input=tmp_file.name, ...)
        os.unlink(tmp_file.name)  # åˆ é™¤ä¸´æ—¶æ–‡ä»¶
        return result
    
    # æ–¹æ¡ˆ2ï¼šç›´æ¥ä¼ å…¥ numpy arrayï¼ˆå¦‚æœæ”¯æŒï¼‰
    # result = sense_model.generate(input=audio_segment, ...)
```

#### 2.2.3 ç»“æœåˆå¹¶

```python
def merge_results(paraformer_result, sensevoice_results):
    """
    åˆå¹¶ Paraformer çš„è¯´è¯äººä¿¡æ¯å’Œ SenseVoice çš„æ–‡æœ¬
    
    Args:
        paraformer_result: Paraformer çš„è¾“å‡ºï¼ˆåŒ…å« sentence_infoï¼‰
        sensevoice_results: æ¯ä¸ªç‰‡æ®µå¯¹åº”çš„ SenseVoice è¾“å‡ºåˆ—è¡¨
    
    Returns:
        merged_results: åˆå¹¶åçš„ç»“æœåˆ—è¡¨
    """
    merged = []
    sentence_info = paraformer_result['sentence_info']
    
    for i, sent_info in enumerate(sentence_info):
        # è·å–è¯´è¯äººID
        spk_id = sent_info['spk']
        
        # è·å– SenseVoice è¯†åˆ«çš„æ–‡æœ¬
        if i < len(sensevoice_results):
            sense_text = sensevoice_results[i]
        else:
            sense_text = sent_info['text']  # é™çº§ä½¿ç”¨ Paraformer çš„æ–‡æœ¬
        
        merged.append({
            'spk_id': spk_id,
            'start': sent_info['start'],
            'end': sent_info['end'],
            'text': sense_text  # æ¥è‡ª SenseVoiceï¼ŒåŒ…å«æƒ…æ„Ÿæ ‡ç­¾
        })
    
    return merged
```

## ä¸‰ã€è¯¦ç»†å®ç°æ­¥éª¤

### 3.1 æ ¸å¿ƒå‡½æ•°å®ç°

```python
def process_audio_cascaded(audio_path, paraformer_model, sensevoice_model):
    """
    çº§è”å¤„ç†éŸ³é¢‘ï¼šå…ˆ Paraformer åš diarizationï¼Œå†ç”¨ SenseVoice è¯†åˆ«
    
    Args:
        audio_path: éŸ³é¢‘æ–‡ä»¶è·¯å¾„
        paraformer_model: Paraformer + Cam++ æ¨¡å‹
        sensevoice_model: SenseVoice æ¨¡å‹
    
    Returns:
        final_results: æœ€ç»ˆç»“æœåˆ—è¡¨
    """
    # === æ­¥éª¤ 1: Paraformer å¤„ç†ï¼ˆè·å–æ—¶é—´æˆ³å’Œè¯´è¯äººIDï¼‰ ===
    print("ğŸ”„ æ­¥éª¤ 1/3: ä½¿ç”¨ Paraformer è¿›è¡Œè¯´è¯äººåŒºåˆ†...")
    paraformer_res = paraformer_model.generate(
        input=audio_path,
        cache={},
        language="auto",
        use_itn=True,
        batch_size_s=60,
        merge_vad=True,
    )
    
    if not paraformer_res or len(paraformer_res) == 0:
        raise ValueError("Paraformer å¤„ç†å¤±è´¥")
    
    paraformer_result = paraformer_res[0]
    sentence_info = paraformer_result.get('sentence_info', [])
    
    if not sentence_info:
        raise ValueError("æœªæ£€æµ‹åˆ°å¥å­ä¿¡æ¯")
    
    print(f"âœ… æ£€æµ‹åˆ° {len(sentence_info)} ä¸ªå¥å­ç‰‡æ®µ")
    
    # === æ­¥éª¤ 2: æå–éŸ³é¢‘ç‰‡æ®µå¹¶ç”¨ SenseVoice é‡æ–°è¯†åˆ« ===
    print("ğŸ”„ æ­¥éª¤ 2/3: æå–éŸ³é¢‘ç‰‡æ®µå¹¶ç”¨ SenseVoice é‡æ–°è¯†åˆ«...")
    sensevoice_results = []
    
    for idx, sent_info in enumerate(sentence_info):
        start_ms = sent_info['start']
        end_ms = sent_info['end']
        
        print(f"  å¤„ç†ç‰‡æ®µ {idx+1}/{len(sentence_info)}: {start_ms}ms - {end_ms}ms")
        
        # æå–éŸ³é¢‘ç‰‡æ®µ
        audio_segment, sample_rate = extract_audio_segment(
            audio_path, start_ms, end_ms
        )
        
        # ä½¿ç”¨ SenseVoice è¯†åˆ«
        sense_res = sensevoice_model.generate(
            input=audio_segment,  # æˆ–ä¸´æ—¶æ–‡ä»¶è·¯å¾„
            cache={},
            language="auto",
            use_itn=True,
        )
        
        # æå–æ–‡æœ¬
        if sense_res and len(sense_res) > 0:
            if isinstance(sense_res[0], dict):
                text = sense_res[0].get('text', '')
            else:
                text = str(sense_res[0])
        else:
            text = sent_info['text']  # é™çº§ä½¿ç”¨ Paraformer çš„æ–‡æœ¬
        
        sensevoice_results.append(text)
    
    # === æ­¥éª¤ 3: åˆå¹¶ç»“æœ ===
    print("ğŸ”„ æ­¥éª¤ 3/3: åˆå¹¶ç»“æœ...")
    final_results = merge_results(paraformer_result, sensevoice_results)
    
    return final_results
```

### 3.2 æ¨¡å‹åˆå§‹åŒ–

```python
def setup_cascaded_models():
    """
    åˆå§‹åŒ–çº§è”ç³»ç»Ÿæ‰€éœ€çš„æ¨¡å‹
    """
    print("ğŸ”„ æ­£åœ¨åŠ è½½ Paraformer + Cam++ æ¨¡å‹...")
    paraformer_model = AutoModel(
        model="paraformer-zh",
        vad_model="fsmn-vad",
        punc_model="ct-punc",
        spk_model="cam++",
        device="cpu",
        ncpu=4,
        disable_update=True
    )
    
    print("ğŸ”„ æ­£åœ¨åŠ è½½ SenseVoice æ¨¡å‹...")
    sensevoice_model = AutoModel(
        model="iic/SenseVoiceSmall",
        trust_remote_code=True,
        vad_model="fsmn-vad",
        vad_kwargs={"max_single_segment_time": 30000},
        punc_model="ct-punc",
        device="cpu",
        ncpu=4,
        disable_update=True
    )
    
    return paraformer_model, sensevoice_model
```

### 3.3 è¾“å‡ºæ ¼å¼åŒ–

```python
def format_cascaded_result(final_results, audio_file):
    """
    æ ¼å¼åŒ–çº§è”ç³»ç»Ÿçš„è¾“å‡ºç»“æœ
    """
    output_lines = []
    output_lines.append(f"éŸ³é¢‘æ–‡ä»¶: {os.path.basename(audio_file)}\n")
    output_lines.append("="*60 + "\n")
    output_lines.append("ğŸ“¢ è¯´è¯äººåŒºåˆ†ç»“æœï¼ˆä½¿ç”¨ SenseVoice è¯†åˆ«ï¼‰:\n")
    output_lines.append("-"*60 + "\n")
    
    for result in final_results:
        spk_id = result['spk_id']
        text = result['text']
        # ç§»é™¤ emojiï¼ˆå¦‚æœéœ€è¦ï¼‰
        text = remove_emoji(text)
        
        output_lines.append(f"è¯´è¯äºº {spk_id}: {text}\n")
    
    return "".join(output_lines)
```

## å››ã€é›†æˆåˆ°ç°æœ‰ç³»ç»Ÿ

### 4.1 GUI ç•Œé¢ä¿®æ”¹

åœ¨ GUI ä¸­æ·»åŠ æ–°çš„å¤„ç†æ¨¡å¼é€‰é¡¹ï¼š

```python
# åœ¨ create_widgets ä¸­æ·»åŠ 
processing_mode_frame = ttk.LabelFrame(main_frame, text="å¤„ç†æ¨¡å¼", padding="10")
processing_mode_frame.grid(row=5, column=0, columnspan=3, sticky=(tk.W, tk.E), pady=5)

self.processing_mode = tk.StringVar(value="direct")  # "direct" æˆ– "cascaded"

ttk.Radiobutton(
    processing_mode_frame,
    text="ç›´æ¥æ¨¡å¼ï¼ˆå•ä¸€æ¨¡å‹ï¼‰",
    variable=self.processing_mode,
    value="direct"
).grid(row=0, column=0, padx=10, sticky=tk.W)

ttk.Radiobutton(
    processing_mode_frame,
    text="çº§è”æ¨¡å¼ï¼ˆParaformer + SenseVoiceï¼‰",
    variable=self.processing_mode,
    value="cascaded"
).grid(row=0, column=1, padx=10, sticky=tk.W)

info_label = ttk.Label(
    processing_mode_frame,
    text="çº§è”æ¨¡å¼ï¼šå…ˆç”¨ Paraformer åšè¯´è¯äººåŒºåˆ†ï¼Œå†ç”¨ SenseVoice è¯†åˆ«æ–‡æœ¬ï¼ˆä¿ç•™æƒ…æ„Ÿæ ‡ç­¾ï¼‰",
    foreground="gray",
    font=("Arial", 9)
)
info_label.grid(row=1, column=0, columnspan=2, padx=10, pady=5, sticky=tk.W)
```

### 4.2 å‘½ä»¤è¡Œè„šæœ¬ä¿®æ”¹

æ·»åŠ å‘½ä»¤è¡Œå‚æ•°æˆ–é…ç½®é€‰é¡¹ï¼š

```python
# åœ¨é…ç½®åŒºåŸŸæ·»åŠ 
ENABLE_CASCADED_MODE = False  # æ˜¯å¦å¯ç”¨çº§è”æ¨¡å¼

# åœ¨ process_audio å‡½æ•°ä¸­æ·»åŠ æ¨¡å¼åˆ¤æ–­
if ENABLE_CASCADED_MODE:
    result = process_audio_cascaded(audio_file, paraformer_model, sensevoice_model)
else:
    result = process_audio_direct(model, audio_file)
```

## äº”ã€æ€§èƒ½ä¼˜åŒ–å»ºè®®

### 5.1 æ‰¹é‡å¤„ç†ä¼˜åŒ–

- **å¹¶è¡Œå¤„ç†ç‰‡æ®µ**ï¼šä½¿ç”¨å¤šçº¿ç¨‹/å¤šè¿›ç¨‹å¹¶è¡Œå¤„ç†å¤šä¸ªéŸ³é¢‘ç‰‡æ®µ
- **ç¼“å­˜æœºåˆ¶**ï¼šç¼“å­˜å·²åŠ è½½çš„æ¨¡å‹ï¼Œé¿å…é‡å¤åŠ è½½

### 5.2 å†…å­˜ä¼˜åŒ–

- **æµå¼å¤„ç†**ï¼šå¯¹äºé•¿éŸ³é¢‘ï¼Œå¯ä»¥æµå¼å¤„ç†ï¼Œé¿å…ä¸€æ¬¡æ€§åŠ è½½æ‰€æœ‰ç‰‡æ®µ
- **ä¸´æ—¶æ–‡ä»¶æ¸…ç†**ï¼šåŠæ—¶åˆ é™¤ä¸´æ—¶æ–‡ä»¶ï¼Œé‡Šæ”¾ç£ç›˜ç©ºé—´

### 5.3 é”™è¯¯å¤„ç†

- **é™çº§ç­–ç•¥**ï¼šå¦‚æœ SenseVoice è¯†åˆ«å¤±è´¥ï¼Œé™çº§ä½¿ç”¨ Paraformer çš„æ–‡æœ¬
- **è¶…æ—¶å¤„ç†**ï¼šä¸ºæ¯ä¸ªç‰‡æ®µè®¾ç½®è¶…æ—¶æ—¶é—´ï¼Œé¿å…å¡æ­»

## å…­ã€æµ‹è¯•è®¡åˆ’

### 6.1 å•å…ƒæµ‹è¯•

1. æµ‹è¯•éŸ³é¢‘ç‰‡æ®µæå–å‡½æ•°
2. æµ‹è¯•ç»“æœåˆå¹¶å‡½æ•°
3. æµ‹è¯•è¾“å‡ºæ ¼å¼åŒ–å‡½æ•°

### 6.2 é›†æˆæµ‹è¯•

1. æµ‹è¯•å®Œæ•´çš„çº§è”æµç¨‹
2. æµ‹è¯•ä¸åŒé•¿åº¦çš„éŸ³é¢‘æ–‡ä»¶
3. æµ‹è¯•å¤šè¯´è¯äººåœºæ™¯

### 6.3 æ€§èƒ½æµ‹è¯•

1. å¯¹æ¯”çº§è”æ¨¡å¼ä¸ç›´æ¥æ¨¡å¼çš„æ€§èƒ½
2. æµ‹è¯•å†…å­˜ä½¿ç”¨æƒ…å†µ
3. æµ‹è¯•å¤„ç†æ—¶é—´

## ä¸ƒã€å®æ–½ä¼˜å…ˆçº§

### Phase 1: æ ¸å¿ƒåŠŸèƒ½å®ç°ï¼ˆé«˜ä¼˜å…ˆçº§ï¼‰
1. âœ… å®ç°éŸ³é¢‘ç‰‡æ®µæå–å‡½æ•°
2. âœ… å®ç°çº§è”å¤„ç†æ ¸å¿ƒé€»è¾‘
3. âœ… å®ç°ç»“æœåˆå¹¶å’Œæ ¼å¼åŒ–

### Phase 2: é›†æˆåˆ°ç°æœ‰ç³»ç»Ÿï¼ˆä¸­ä¼˜å…ˆçº§ï¼‰
1. âœ… æ›´æ–°å‘½ä»¤è¡Œè„šæœ¬
2. âœ… æ›´æ–° GUI ç•Œé¢
3. âœ… æ·»åŠ é…ç½®é€‰é¡¹

### Phase 3: ä¼˜åŒ–å’Œæµ‹è¯•ï¼ˆä½ä¼˜å…ˆçº§ï¼‰
1. â³ æ€§èƒ½ä¼˜åŒ–
2. â³ é”™è¯¯å¤„ç†å®Œå–„
3. â³ æ–‡æ¡£å’Œæµ‹è¯•

## å…«ã€å·²çŸ¥é—®é¢˜å’Œè§£å†³æ–¹æ¡ˆ

### 8.1 éŸ³é¢‘æ ¼å¼å…¼å®¹æ€§

**é—®é¢˜**ï¼šä¸åŒéŸ³é¢‘æ ¼å¼å¯èƒ½éœ€è¦ä¸åŒçš„å¤„ç†æ–¹å¼

**è§£å†³æ–¹æ¡ˆ**ï¼š
- ä½¿ç”¨ soundfile ç»Ÿä¸€å¤„ç†ï¼ˆæ”¯æŒå¤šç§æ ¼å¼ï¼‰
- å¦‚æœé‡åˆ°ä¸æ”¯æŒçš„æ ¼å¼ï¼Œä½¿ç”¨ ffmpeg è½¬æ¢

### 8.2 SenseVoice è¾“å…¥æ ¼å¼

**é—®é¢˜**ï¼šSenseVoice çš„ `generate` æ–¹æ³•å¯èƒ½ä¸æ”¯æŒç›´æ¥ä¼ å…¥ numpy array

**è§£å†³æ–¹æ¡ˆ**ï¼š
- å…ˆæµ‹è¯•æ˜¯å¦æ”¯æŒ numpy array
- å¦‚æœä¸æ”¯æŒï¼Œä½¿ç”¨ä¸´æ—¶æ–‡ä»¶

### 8.3 æ—¶é—´æˆ³ç²¾åº¦

**é—®é¢˜**ï¼šæ¯«ç§’çº§æ—¶é—´æˆ³å¯èƒ½å­˜åœ¨ç²¾åº¦è¯¯å·®

**è§£å†³æ–¹æ¡ˆ**ï¼š
- åœ¨æå–ç‰‡æ®µæ—¶æ·»åŠ å‰åç¼“å†²ï¼ˆå¦‚å‰åå„ 100msï¼‰
- ç¡®ä¿æå–çš„ç‰‡æ®µåŒ…å«å®Œæ•´çš„è¯­éŸ³å†…å®¹

## ä¹ã€å‚è€ƒèµ„æ–™

1. FunASR å®˜æ–¹æ–‡æ¡£ï¼šhttps://github.com/modelscope/FunASR
2. soundfile æ–‡æ¡£ï¼šhttps://pysoundfile.readthedocs.io/
3. Paraformer æ¨¡å‹è¯´æ˜ï¼šhttps://modelscope.cn/models/iic/speech_seaco_paraformer_large_asr_nat-zh-cn-16k-common-vocab8404-pytorch
4. SenseVoice æ¨¡å‹è¯´æ˜ï¼šhttps://modelscope.cn/models/iic/SenseVoiceSmall

## åã€æ€»ç»“

è¿™ä¸ªçº§è”ç³»ç»Ÿæ–¹æ¡ˆå……åˆ†åˆ©ç”¨äº† Paraformer å’Œ SenseVoice å„è‡ªçš„ä¼˜åŠ¿ï¼š
- âœ… Paraformerï¼šæ“…é•¿è¯´è¯äººåŒºåˆ†å’Œæ—¶é—´æˆ³å®šä½
- âœ… SenseVoiceï¼šæ“…é•¿æ–‡æœ¬è¯†åˆ«å’Œæƒ…æ„Ÿæ ‡ç­¾

é€šè¿‡"å…ˆå®šä½å®šäººï¼Œå†è¯†åˆ«å†…å®¹"çš„ç­–ç•¥ï¼Œå®ç°äº†ï¼š
- âœ… è¯´è¯äººåŒºåˆ†åŠŸèƒ½
- âœ… é«˜å‡†ç¡®ç‡çš„æ–‡æœ¬è¯†åˆ«
- âœ… æƒ…æ„Ÿæ ‡ç­¾ä¿ç•™
- âœ… ä¸è¾“å‡ºæ—¶é—´æˆ³ï¼ˆæ ¹æ®ç”¨æˆ·éœ€æ±‚ï¼‰

è¯¥æ–¹æ¡ˆå®Œå…¨å¯è¡Œï¼Œå»ºè®®æŒ‰ç…§ä¸Šè¿°è®¡åˆ’é€æ­¥å®æ–½ã€‚



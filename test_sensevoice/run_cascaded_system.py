"""
çº§è”ç³»ç»Ÿ v3ï¼šé”šç‚¹åˆ†æ®µ + æ™ºèƒ½å¯¹é½
å®ç°"ç”¨ Paraformer å®šä½å®šäººï¼Œç”¨ SenseVoice ä¿®æ­£å†…å®¹"çš„æ–¹æ¡ˆ

æ”¹è¿›å†…å®¹ï¼š
- é”šç‚¹åˆ†æ®µï¼šé¿å…å¯¹é½æ¼‚ç§»è·¨æ®µä¼ æ’­
- è·ç¦»çº¦æŸï¼šé˜²æ­¢å¹»è§‰å¯¼è‡´çš„æŒ‡é’ˆè·³è·ƒ
- å¹»è§‰æ£€æµ‹ï¼šè¯†åˆ«é‡å¤å­—ç¬¦ç­‰å¼‚å¸¸è¾“å‡º
- åˆ†å±‚ç­–ç•¥ï¼šå•ç‰‡æ®µ/å¤šè¯´è¯äºº/åŒè¯´è¯äººåˆ†åˆ«å¤„ç†
"""

import os
import time
import re
import tempfile
import traceback
import difflib
import numpy as np
from funasr import AutoModel
from funasr.utils.postprocess_utils import rich_transcription_postprocess

# å°è¯•å¯¼å…¥éŸ³é¢‘å¤„ç†åº“ï¼ˆä¼˜å…ˆä½¿ç”¨ soundfileï¼Œå¦‚æœä¸æ”¯æŒæ ¼å¼åˆ™ä½¿ç”¨ librosaï¼‰
try:
    import soundfile as sf
    USE_SOUNDFILE = True
except ImportError:
    USE_SOUNDFILE = False

try:
    import librosa
    USE_LIBROSA = True
except ImportError:
    USE_LIBROSA = False
    if not USE_SOUNDFILE:
        raise ImportError("éœ€è¦å®‰è£… soundfile æˆ– librosa åº“")

# ================= é…ç½®åŒºåŸŸ =================
DEVICE = "cpu"
THREADS = 4
DEFAULT_OUTPUT_DIR = "/Users/zhengyidi/AutoVoice/recordings"

# v3 é…ç½®
MAX_SEGMENT_DURATION_MS = 5 * 60 * 1000  # æœ€å¤§å¯¹é½æ®µæ—¶é•¿ï¼š5åˆ†é’Ÿ
MIN_SILENCE_GAP_MS = 2000  # é”šç‚¹æ¡ä»¶ï¼šé™éŸ³è¶…è¿‡2ç§’
MIN_SIMILARITY_THRESHOLD = 0.5  # æœ€ä½ç›¸ä¼¼åº¦é˜ˆå€¼
# ===========================================


def remove_emoji(text):
    """ç§»é™¤æ–‡æœ¬ä¸­çš„ emojiï¼Œä¿ç•™æ ‡ç‚¹ç¬¦å·å’ŒåŸºæœ¬å­—ç¬¦ï¼ˆåŒ…æ‹¬ä¸­æ–‡ï¼‰"""
    emoji_pattern = re.compile(
        "["
        "\U0001F600-\U0001F64F"  # è¡¨æƒ…ç¬¦å·
        "\U0001F300-\U0001F5FF"  # ç¬¦å·å’Œè±¡å½¢æ–‡å­—
        "\U0001F680-\U0001F6FF"  # äº¤é€šå’Œåœ°å›¾ç¬¦å·
        "\U0001F1E0-\U0001F1FF"  # æ——å¸œ
        "\U00002702-\U000027B0"  # å…¶ä»–ç¬¦å·
        "\U0001F900-\U0001F9FF"  # è¡¥å……ç¬¦å·å’Œè±¡å½¢æ–‡å­—
        "\U0001FA00-\U0001FA6F"  # æ‰©å±•ç¬¦å·
        "\U0001FA70-\U0001FAFF"  # æ‰©å±•ç¬¦å·
        "\U00002600-\U000026FF"  # æ‚é¡¹ç¬¦å·
        "\U00002700-\U000027BF"  # è£…é¥°ç¬¦å·
        "]+",
        flags=re.UNICODE
    )
    return emoji_pattern.sub('', text).strip()


def remove_sensevoice_tags(text):
    """ç§»é™¤ SenseVoice è¾“å‡ºçš„æ ‡ç­¾ï¼Œåªä¿ç•™çº¯æ–‡æœ¬"""
    if not text:
        return ""
    tag_pattern = re.compile(r'<\s*\|[^|]*\|\s*>')
    text = tag_pattern.sub('', text)
    text = re.sub(r'\s+', ' ', text)
    return text.strip()


def normalize_text(text):
    """
    æ–‡æœ¬æ ‡å‡†åŒ–ï¼Œç”¨äºæ¨¡ç³ŠåŒ¹é…
    - ç§»é™¤æ ‡ç‚¹ç¬¦å·
    - è½¬æ¢ä¸ºå°å†™ï¼ˆé’ˆå¯¹è‹±æ–‡ï¼‰
    """
    if not text:
        return ""
    # ç§»é™¤æ‰€æœ‰æ ‡ç‚¹ç¬¦å·å’Œç©ºæ ¼
    text = re.sub(r'[ï¼Œã€‚ï¼ï¼Ÿã€ï¼šï¼›""''ï¼ˆï¼‰ã€ã€‘ã€Šã€‹â€¦â€”\s,.!?;:\'"()\[\]{}\n\r\t]+', '', text)
    # è½¬æ¢ä¸ºå°å†™
    text = text.lower()
    return text


def extract_audio_segment(audio_path, start_ms, end_ms, buffer_ms=100):
    """æå–éŸ³é¢‘ç‰‡æ®µ"""
    start_ms = max(0, start_ms - buffer_ms)
    end_ms = end_ms + buffer_ms
    
    if USE_SOUNDFILE:
        try:
            audio_data, sample_rate = sf.read(audio_path)
            start_sample = int(start_ms * sample_rate / 1000)
            end_sample = int(end_ms * sample_rate / 1000)
            start_sample = max(0, start_sample)
            end_sample = min(len(audio_data), end_sample)
            segment = audio_data[start_sample:end_sample]
            return segment, sample_rate
        except Exception:
            pass
    
    if USE_LIBROSA:
        start_sec = start_ms / 1000.0
        end_sec = end_ms / 1000.0
        duration = end_sec - start_sec
        audio_data, sample_rate = librosa.load(
            audio_path, offset=start_sec, duration=duration, sr=None
        )
        return audio_data, sample_rate
    
    raise RuntimeError("æ— æ³•è¯»å–éŸ³é¢‘æ–‡ä»¶ï¼šsoundfile å’Œ librosa éƒ½ä¸å¯ç”¨")


# ==================== v3 æ–°å¢å‡½æ•° ====================

def find_alignment_anchors(sentence_info, max_segment_duration_ms=MAX_SEGMENT_DURATION_MS):
    """
    è¯†åˆ«å¯¹é½é”šç‚¹
    
    é”šç‚¹ç±»å‹ï¼š
    1. é•¿é™éŸ³æ®µ (gap > MIN_SILENCE_GAP_MS)
    2. è¯´è¯äººåˆ‡æ¢ç‚¹
    3. å¼ºåˆ¶é”šç‚¹ (æ¯ max_segment_duration_ms æ¯«ç§’)
    
    è¿”å›ï¼šé”šç‚¹ç´¢å¼•åˆ—è¡¨ï¼ˆç”¨äºåˆ‡åˆ† sentence_infoï¼‰
    """
    if not sentence_info:
        return [0, 0]
    
    anchors = [0]  # èµ·å§‹é”šç‚¹
    last_anchor_time = sentence_info[0]['start']
    
    for i in range(1, len(sentence_info)):
        prev = sentence_info[i-1]
        curr = sentence_info[i]
        
        # é”šç‚¹æ¡ä»¶ 1: é•¿é™éŸ³
        gap = curr['start'] - prev['end']
        if gap > MIN_SILENCE_GAP_MS:
            anchors.append(i)
            last_anchor_time = curr['start']
            continue
        
        # é”šç‚¹æ¡ä»¶ 2: è¯´è¯äººåˆ‡æ¢
        if prev.get('spk') != curr.get('spk'):
            anchors.append(i)
            last_anchor_time = curr['start']
            continue
        
        # é”šç‚¹æ¡ä»¶ 3: å¼ºåˆ¶é—´éš”
        if curr['start'] - last_anchor_time > max_segment_duration_ms:
            anchors.append(i)
            last_anchor_time = curr['start']
    
    anchors.append(len(sentence_info))  # ç»“æŸé”šç‚¹
    
    # å»é‡å¹¶æ’åº
    anchors = sorted(list(set(anchors)))
    return anchors


def is_likely_hallucination(para_text, match_result=None, remaining_text_len=0):
    """
    æ£€æµ‹ Paraformer è¾“å‡ºæ˜¯å¦å¯èƒ½æ˜¯å¹»è§‰
    
    å¹»è§‰ç‰¹å¾ï¼š
    1. æ–‡æœ¬å¾ˆçŸ­ä½†é‡å¤ï¼ˆå¦‚ "é˜¿å·´é˜¿å·´"ï¼‰
    2. åœ¨ SenseVoice æ–‡æœ¬ä¸­æ‰¾ä¸åˆ°ç›¸ä¼¼å†…å®¹
    3. åŒ¹é…ä½ç½®å¼‚å¸¸é å
    """
    if not para_text:
        return True
    
    # ç‰¹å¾ 1: é‡å¤å­—ç¬¦æ£€æµ‹
    if len(para_text) >= 4:
        unique_chars = len(set(para_text))
        if unique_chars <= 2:  # åªæœ‰ 1-2 ç§å­—ç¬¦
            return True
    
    # ç‰¹å¾ 2: æ— åŒ¹é…æˆ–ä½ç›¸ä¼¼åº¦
    if match_result is None:
        return True
    
    if match_result.get('similarity', 0) < 0.4:
        return True
    
    # ç‰¹å¾ 3: åŒ¹é…ä½ç½®å¼‚å¸¸ï¼ˆè¶…è¿‡å‰©ä½™æ–‡æœ¬çš„ä¸€åŠï¼‰
    if remaining_text_len > 0:
        if match_result.get('start_pos', 0) > remaining_text_len * 0.5:
            return True
    
    return False


def fuzzy_substring_search(haystack, needle, min_similarity=MIN_SIMILARITY_THRESHOLD, max_search_distance=None):
    """
    å¸¦è·ç¦»çº¦æŸçš„æ¨¡ç³Šå­ä¸²æœç´¢
    
    Args:
        haystack: å¾…æœç´¢çš„æ–‡æœ¬ï¼ˆSenseVoice è¾“å‡ºï¼‰
        needle: è¦æŸ¥æ‰¾çš„æ¨¡å¼ï¼ˆParaformer ç‰‡æ®µæ–‡æœ¬ï¼‰
        min_similarity: æœ€ä½ç›¸ä¼¼åº¦é˜ˆå€¼
        max_search_distance: æœ€å¤§æœç´¢è·ç¦»ï¼ˆå­—ç¬¦æ•°ï¼‰
    
    Returns:
        åŒ¹é…ç»“æœå­—å…¸ï¼Œæˆ– None
    """
    needle_normalized = normalize_text(needle)
    
    if not needle_normalized:
        return None
    
    needle_len = len(needle_normalized)
    
    # è·ç¦»çº¦æŸï¼šé»˜è®¤ä¸º needle é•¿åº¦çš„ 3 å€ï¼Œæœ€å°‘ 50 å­—ç¬¦
    if max_search_distance is None:
        max_search_distance = max(needle_len * 3, 50)
    
    # åªæœç´¢ haystack çš„å‰ max_search_distance ä¸ªå­—ç¬¦
    search_text = haystack[:max_search_distance]
    search_normalized = normalize_text(search_text)
    
    if not search_normalized:
        return None
    
    best_match = None
    best_score = 0
    
    # æ»‘åŠ¨çª—å£æœç´¢
    for window_size in range(
        max(1, int(needle_len * 0.5)),
        min(len(search_normalized), int(needle_len * 2)) + 1
    ):
        for start in range(len(search_normalized) - window_size + 1):
            candidate = search_normalized[start:start + window_size]
            score = difflib.SequenceMatcher(None, needle_normalized, candidate).ratio()
            
            if score > best_score:
                best_score = score
                best_match = {
                    'start_pos': start,
                    'end_pos': start + window_size,
                    'similarity': score
                }
    
    if best_match and best_match['similarity'] >= min_similarity:
        # æ˜ å°„å›åŸå§‹æ–‡æœ¬ï¼ˆåŒ…å«æ ‡ç‚¹ï¼‰
        original_start = map_to_original_pos(search_text, best_match['start_pos'])
        original_end = map_to_original_pos(search_text, best_match['end_pos'])
        
        return {
            'text': haystack[original_start:original_end],
            'start_pos': original_start,
            'end_pos': original_end,
            'similarity': best_match['similarity']
        }
    
    return None


def map_to_original_pos(original_text, normalized_pos):
    """å°†æ ‡å‡†åŒ–æ–‡æœ¬ä¸­çš„ä½ç½®æ˜ å°„å›åŸå§‹æ–‡æœ¬"""
    normalized_idx = 0
    for original_idx, char in enumerate(original_text):
        if not re.match(r'[ï¼Œã€‚ï¼ï¼Ÿã€ï¼šï¼›""''ï¼ˆï¼‰ã€ã€‘ã€Šã€‹â€¦â€”\s,.!?;:\'"()\[\]{}\n\r\t]', char):
            if normalized_idx == normalized_pos:
                return original_idx
            normalized_idx += 1
    return len(original_text)


def merge_same_speaker_segments(segments):
    """
    åˆå¹¶è¿ç»­çš„åŒè¯´è¯äººç‰‡æ®µ
    å‡å°‘éœ€è¦å¯¹é½çš„å•å…ƒæ•°é‡ï¼Œæé«˜åŒ¹é…å‡†ç¡®åº¦
    """
    if not segments:
        return []
    
    merged = []
    current_group = {
        'spk': segments[0].get('spk'),
        'start': segments[0]['start'],
        'end': segments[0]['end'],
        'text': segments[0].get('text', ''),
        'original_segments': [segments[0]]
    }
    
    for seg in segments[1:]:
        if seg.get('spk') == current_group['spk']:
            # åŒè¯´è¯äººï¼Œåˆå¹¶
            current_group['end'] = seg['end']
            current_group['text'] += seg.get('text', '')
            current_group['original_segments'].append(seg)
        else:
            # ä¸åŒè¯´è¯äººï¼Œä¿å­˜å½“å‰ç»„ï¼Œå¼€å§‹æ–°ç»„
            merged.append(current_group)
            current_group = {
                'spk': seg.get('spk'),
                'start': seg['start'],
                'end': seg['end'],
                'text': seg.get('text', ''),
                'original_segments': [seg]
            }
    
    merged.append(current_group)
    return merged


def group_by_speaker(segments):
    """æŒ‰è¯´è¯äººåˆ†ç»„ï¼ˆä¿æŒé¡ºåºï¼‰"""
    return merge_same_speaker_segments(segments)


def sequential_fuzzy_match(sensevoice_text, speaker_groups, log=print):
    """
    å¸¦é¡ºåºçº¦æŸå’Œè·ç¦»çº¦æŸçš„æ¨¡ç³ŠåŒ¹é…
    
    åŒé‡ä¿æŠ¤ï¼š
    1. é¡ºåºçº¦æŸï¼šåªåœ¨ current_pos ä¹‹åæœç´¢
    2. è·ç¦»çº¦æŸï¼šåªåœ¨åˆç†èŒƒå›´å†…æœç´¢ï¼Œé¿å…å¹»è§‰å¯¼è‡´çš„è·³è·ƒ
    """
    results = []
    current_pos = 0
    total_len = len(sensevoice_text)
    
    for group in speaker_groups:
        para_text = group.get('text', '')
        para_len = len(normalize_text(para_text))
        
        if para_len == 0:
            # ç©ºæ–‡æœ¬ï¼Œè·³è¿‡
            results.append({
                'spk': group['spk'],
                'start': group['start'],
                'end': group['end'],
                'text': '',
                'original_segments': group.get('original_segments', []),
                'source': 'empty'
            })
            continue
        
        # åªåœ¨ current_pos ä¹‹åæœç´¢
        remaining_text = sensevoice_text[current_pos:]
        remaining_len = len(remaining_text)
        
        # è®¡ç®—åˆç†çš„æœç´¢è·ç¦»
        max_search_distance = max(para_len * 3, 50)
        
        match = fuzzy_substring_search(
            haystack=remaining_text,
            needle=para_text,
            min_similarity=MIN_SIMILARITY_THRESHOLD,
            max_search_distance=max_search_distance
        )
        
        # æ£€æŸ¥æ˜¯å¦å¯èƒ½æ˜¯å¹»è§‰
        if is_likely_hallucination(para_text, match, remaining_len):
            # å¯èƒ½æ˜¯å¹»è§‰ï¼Œä½¿ç”¨ Paraformer åŸæ–‡ï¼Œå°æ­¥å‰è¿›
            results.append({
                'spk': group['spk'],
                'start': group['start'],
                'end': group['end'],
                'text': remove_emoji(para_text),
                'original_segments': group.get('original_segments', []),
                'source': 'paraformer_hallucination'
            })
            # å°æ­¥å‰è¿›
            current_pos += min(para_len, 20)
            continue
        
        if match:
            # æ£€æŸ¥åŒ¹é…ä½ç½®æ˜¯å¦åˆç†
            if match['start_pos'] > max_search_distance * 0.8:
                # åŒ¹é…ä½ç½®æ¥è¿‘æœç´¢è¾¹ç•Œï¼Œå¯èƒ½æ˜¯è¯¯åŒ¹é…
                results.append({
                    'spk': group['spk'],
                    'start': group['start'],
                    'end': group['end'],
                    'text': remove_emoji(para_text),
                    'original_segments': group.get('original_segments', []),
                    'source': 'paraformer_suspicious'
                })
                current_pos += min(para_len, 20)
            else:
                # æ­£å¸¸åŒ¹é…
                absolute_end = current_pos + match['end_pos']
                matched_text = match['text'].strip()
                
                results.append({
                    'spk': group['spk'],
                    'start': group['start'],
                    'end': group['end'],
                    'text': matched_text if matched_text else remove_emoji(para_text),
                    'original_segments': group.get('original_segments', []),
                    'similarity': match['similarity'],
                    'source': 'sensevoice_fuzzy'
                })
                current_pos = absolute_end
        else:
            # åŒ¹é…å¤±è´¥ï¼Œä½¿ç”¨ Paraformer åŸæ–‡
            results.append({
                'spk': group['spk'],
                'start': group['start'],
                'end': group['end'],
                'text': remove_emoji(para_text),
                'original_segments': group.get('original_segments', []),
                'source': 'paraformer_fallback'
            })
            current_pos += min(para_len, 20)
    
    return results


def expand_merged_results(merged_results):
    """
    å°†åˆå¹¶çš„ç»“æœå±•å¼€å›åŸå§‹ç‰‡æ®µ
    å¯¹äºåŒè¯´è¯äººå¤šç‰‡æ®µï¼Œä¿æŒåˆå¹¶çŠ¶æ€
    """
    expanded = []
    for r in merged_results:
        original_segments = r.get('original_segments', [])
        if len(original_segments) <= 1:
            # å•ç‰‡æ®µæˆ–æ— åŸå§‹ä¿¡æ¯ï¼Œç›´æ¥æ·»åŠ 
            expanded.append({
                'spk_id': r['spk'],
                'start': r['start'],
                'end': r['end'],
                'text': r['text'],
                'source': r.get('source', 'unknown')
            })
        else:
            # å¤šç‰‡æ®µåˆå¹¶ï¼Œä¿æŒåˆå¹¶çŠ¶æ€è¾“å‡º
            expanded.append({
                'spk_id': r['spk'],
                'start': r['start'],
                'end': r['end'],
                'text': r['text'],
                'source': r.get('source', 'unknown'),
                'merged_count': len(original_segments)
            })
    return expanded


# ==================== æ¨¡å‹è®¾ç½® ====================

def setup_cascaded_models():
    """åˆå§‹åŒ–çº§è”ç³»ç»Ÿæ‰€éœ€çš„æ¨¡å‹"""
    print("ğŸ”„ æ­£åœ¨åŠ è½½ Paraformer + Cam++ æ¨¡å‹...")
    start_time = time.time()
    
    paraformer_model = AutoModel(
        model="paraformer-zh",
        vad_model="fsmn-vad",
        punc_model="ct-punc",
        spk_model="cam++",
        device=DEVICE,
        ncpu=THREADS,
        disable_update=True
    )
    
    elapsed = time.time() - start_time
    print(f"âœ… Paraformer + Cam++ æ¨¡å‹åŠ è½½å®Œæˆï¼Œè€—æ—¶: {elapsed:.2f}ç§’")
    
    print("ğŸ”„ æ­£åœ¨åŠ è½½ SenseVoice æ¨¡å‹...")
    start_time = time.time()
    
    sensevoice_model = AutoModel(
        model="iic/SenseVoiceSmall",
        trust_remote_code=True,
        vad_model="fsmn-vad",
        vad_kwargs={"max_single_segment_time": 30000},
        punc_model="ct-punc",
        device=DEVICE,
        ncpu=THREADS,
        disable_update=True
    )
    
    elapsed = time.time() - start_time
    print(f"âœ… SenseVoice æ¨¡å‹åŠ è½½å®Œæˆï¼Œè€—æ—¶: {elapsed:.2f}ç§’")
    
    return paraformer_model, sensevoice_model


# ==================== v3 ä¸»å¤„ç†å‡½æ•° ====================

def process_audio_cascaded(audio_path, paraformer_model, sensevoice_model, log_callback=None, log_detail_callback=None):
    """
    çº§è”å¤„ç† v3ï¼šé”šç‚¹åˆ†æ®µ + æ™ºèƒ½å¯¹é½
    
    Args:
        audio_path: éŸ³é¢‘æ–‡ä»¶è·¯å¾„
        paraformer_model: Paraformer + Cam++ æ¨¡å‹
        sensevoice_model: SenseVoice æ¨¡å‹
        log_callback: æ—¥å¿—å›è°ƒå‡½æ•°ï¼ˆå¯é€‰ï¼‰
        log_detail_callback: è¯¦ç»†æ—¥å¿—å›è°ƒå‡½æ•°ï¼ˆå¯é€‰ï¼‰
    
    Returns:
        final_results: æœ€ç»ˆç»“æœåˆ—è¡¨
    """
    def log(msg, level="main"):
        if log_callback:
            log_callback(msg, level)
        else:
            print(f"[{level}] {msg}")
    
    def log_detail(msg, level="info"):
        if log_detail_callback:
            log_detail_callback(msg, level)
        else:
            print(f"[{level}] {msg}")
    
    total_start_time = time.time()
    
    # === æ­¥éª¤ 1: Paraformer å¤„ç† ===
    log("="*60)
    log("ğŸ”„ æ­¥éª¤ 1/4: ä½¿ç”¨ Paraformer è¿›è¡Œè¯´è¯äººåŒºåˆ†...")
    log("="*60)
    
    para_start_time = time.time()
    paraformer_res = paraformer_model.generate(
        input=audio_path,
        cache={},
        language="auto",
        use_itn=True,
        batch_size_s=60,
        merge_vad=True,
    )
    
    if not paraformer_res or len(paraformer_res) == 0:
        raise ValueError("Paraformer å¤„ç†å¤±è´¥ï¼šæœªè¿”å›ç»“æœ")
    
    paraformer_result = paraformer_res[0]
    sentence_info = paraformer_result.get('sentence_info', [])
    
    if not sentence_info:
        raise ValueError("Paraformer å¤„ç†å¤±è´¥ï¼šæœªæ£€æµ‹åˆ°å¥å­ä¿¡æ¯")
    
    para_elapsed = time.time() - para_start_time
    log(f"âœ… æ£€æµ‹åˆ° {len(sentence_info)} ä¸ªå¥å­ç‰‡æ®µï¼Œè€—æ—¶: {para_elapsed:.2f}ç§’")
    
    # === æ­¥éª¤ 2: è¯†åˆ«å¯¹é½é”šç‚¹ ===
    log("")
    log("="*60)
    log("ğŸ”„ æ­¥éª¤ 2/4: è¯†åˆ«å¯¹é½é”šç‚¹...")
    log("="*60)
    
    anchors = find_alignment_anchors(sentence_info)
    num_segments = len(anchors) - 1
    log(f"ğŸ“Š è¯†åˆ«åˆ° {num_segments} ä¸ªå¯¹é½æ®µ")
    
    # æ˜¾ç¤ºé”šç‚¹åˆ†å¸ƒ
    for i in range(num_segments):
        start_idx = anchors[i]
        end_idx = anchors[i + 1]
        seg_count = end_idx - start_idx
        if seg_count > 0:
            start_time_ms = sentence_info[start_idx]['start']
            end_time_ms = sentence_info[end_idx - 1]['end']
            duration_sec = (end_time_ms - start_time_ms) / 1000
            log(f"  å¯¹é½æ®µ {i+1}: {seg_count} ä¸ªç‰‡æ®µ, {duration_sec:.1f}ç§’ ({start_time_ms}ms - {end_time_ms}ms)", "sub")
    
    # === æ­¥éª¤ 3: åˆ†æ®µå¤„ç† ===
    log("")
    log("="*60)
    log("ğŸ”„ æ­¥éª¤ 3/4: åˆ†æ®µå¤„ç†ï¼ˆParaformer + SenseVoice å¯¹é½ï¼‰...")
    log("="*60)
    
    all_results = []
    sense_total_time = 0
    
    for seg_idx in range(num_segments):
        start_idx = anchors[seg_idx]
        end_idx = anchors[seg_idx + 1]
        segment_infos = sentence_info[start_idx:end_idx]
        
        if not segment_infos:
            continue
        
        # è¯¥æ®µçš„æ—¶é—´èŒƒå›´
        seg_start_ms = segment_infos[0]['start']
        seg_end_ms = segment_infos[-1]['end']
        seg_duration = (seg_end_ms - seg_start_ms) / 1000
        
        log(f"å¤„ç†å¯¹é½æ®µ {seg_idx+1}/{num_segments}: {seg_duration:.1f}ç§’, {len(segment_infos)} ä¸ªç‰‡æ®µ")
        
        # æå–è¯¥æ®µéŸ³é¢‘
        try:
            audio_segment, sr = extract_audio_segment(audio_path, seg_start_ms, seg_end_ms)
        except Exception as e:
            log(f"  âŒ éŸ³é¢‘æå–å¤±è´¥: {str(e)}", "error")
            # é™çº§ï¼šä½¿ç”¨ Paraformer åŸæ–‡
            for seg in segment_infos:
                all_results.append({
                    'spk_id': seg.get('spk', 'unknown'),
                    'start': seg['start'],
                    'end': seg['end'],
                    'text': remove_emoji(seg.get('text', '')),
                    'source': 'paraformer_extract_failed'
                })
            continue
        
        # SenseVoice å¤„ç†è¯¥æ®µ
        sv_text = ""
        try:
            with tempfile.NamedTemporaryFile(suffix='.wav', delete=False) as f:
                tmp_path = f.name
                sf.write(tmp_path, audio_segment, sr)
            
            sense_start = time.time()
            sv_res = sensevoice_model.generate(
                input=tmp_path,
                cache={},
                language="auto",
                use_itn=True,
            )
            sense_total_time += time.time() - sense_start
            
            os.unlink(tmp_path)
            
            # æå– SenseVoice æ–‡æœ¬
            if sv_res:
                if isinstance(sv_res, list) and len(sv_res) > 0:
                    item = sv_res[0]
                    if isinstance(item, dict):
                        sv_text = item.get('text', '')
                    elif isinstance(item, (list, tuple)) and len(item) > 0:
                        sv_text = item[0].get('text', '') if isinstance(item[0], dict) else str(item[0])
                    else:
                        sv_text = str(item)
                elif isinstance(sv_res, dict):
                    sv_text = sv_res.get('text', '')
            
            # åå¤„ç†
            if sv_text:
                sv_text = remove_sensevoice_tags(sv_text)
                sv_text = rich_transcription_postprocess(sv_text)
                sv_text = remove_emoji(sv_text)
                
        except Exception as e:
            log(f"  âŒ SenseVoice å¤„ç†å¤±è´¥: {str(e)}", "error")
            log_detail(traceback.format_exc(), "error")
        
        # === æ­¥éª¤ 4: æ ¹æ®æƒ…å†µé€‰æ‹©å¯¹é½ç­–ç•¥ ===
        
        if not sv_text or not sv_text.strip():
            # SenseVoice å¤±è´¥ï¼Œä½¿ç”¨ Paraformer åŸæ–‡
            log(f"  âš ï¸ SenseVoice è¯†åˆ«ä¸ºç©ºï¼Œä½¿ç”¨ Paraformer åŸæ–‡", "warning")
            for seg in segment_infos:
                text = remove_emoji(seg.get('text', ''))
                if text.strip():
                    all_results.append({
                        'spk_id': seg.get('spk', 'unknown'),
                        'start': seg['start'],
                        'end': seg['end'],
                        'text': text,
                        'source': 'paraformer_sv_empty'
                    })
            continue
        
        if len(segment_infos) == 1:
            # æƒ…å†µ A: å•ç‰‡æ®µ - ç›´æ¥ä½¿ç”¨ SenseVoice æ–‡æœ¬
            seg = segment_infos[0]
            log(f"  âœ… å•ç‰‡æ®µï¼Œç›´æ¥ä½¿ç”¨ SenseVoice: {sv_text[:30]}..." if len(sv_text) > 30 else f"  âœ… å•ç‰‡æ®µ: {sv_text}", "sub")
            all_results.append({
                'spk_id': seg.get('spk', 'unknown'),
                'start': seg['start'],
                'end': seg['end'],
                'text': sv_text,
                'source': 'sensevoice_direct'
            })
        
        else:
            # æ£€æŸ¥æ˜¯å¦å¤šè¯´è¯äºº
            speakers = set(s.get('spk') for s in segment_infos)
            
            if len(speakers) > 1:
                # æƒ…å†µ B: å¤šè¯´è¯äºº - æŒ‰è¯´è¯äººåˆ†ç»„åæ¨¡ç³ŠåŒ¹é…
                log(f"  ğŸ”€ å¤šè¯´è¯äºº ({len(speakers)}äºº)ï¼Œæ‰§è¡Œæ¨¡ç³ŠåŒ¹é…", "sub")
                speaker_groups = group_by_speaker(segment_infos)
                aligned = sequential_fuzzy_match(sv_text, speaker_groups, log)
                expanded = expand_merged_results(aligned)
                all_results.extend(expanded)
            
            else:
                # æƒ…å†µ C: åŒè¯´è¯äººå¤šç‰‡æ®µ - ä¿æŒåˆå¹¶è¾“å‡º
                log(f"  ğŸ“ åŒè¯´è¯äºº {len(segment_infos)} ä¸ªç‰‡æ®µï¼Œä¿æŒåˆå¹¶", "sub")
                all_results.append({
                    'spk_id': segment_infos[0].get('spk', 'unknown'),
                    'start': segment_infos[0]['start'],
                    'end': segment_infos[-1]['end'],
                    'text': sv_text,
                    'source': 'sensevoice_merged',
                    'merged_count': len(segment_infos)
                })
    
    # === å®Œæˆ ===
    total_elapsed = time.time() - total_start_time
    log("")
    log("="*60)
    log(f"âœ… çº§è”å¤„ç†å®Œæˆï¼Œæ€»è€—æ—¶: {total_elapsed:.2f}ç§’")
    log(f"   - Paraformer: {para_elapsed:.2f}ç§’")
    log(f"   - SenseVoice: {sense_total_time:.2f}ç§’")
    log("="*60)
    
    # ç»Ÿè®¡æ¥æº
    source_stats = {}
    for r in all_results:
        src = r.get('source', 'unknown')
        source_stats[src] = source_stats.get(src, 0) + 1
    
    log("ğŸ“Š æ–‡æœ¬æ¥æºç»Ÿè®¡:")
    for src, count in sorted(source_stats.items()):
        log(f"   - {src}: {count}")
    
    return all_results


def format_cascaded_result(final_results, audio_file):
    """æ ¼å¼åŒ–çº§è”ç³»ç»Ÿçš„è¾“å‡ºç»“æœ"""
    output_lines = []
    output_lines.append(f"éŸ³é¢‘æ–‡ä»¶: {os.path.basename(audio_file)}\n")
    output_lines.append("="*60 + "\n")
    output_lines.append("ğŸ“¢ è¯´è¯äººåŒºåˆ†ç»“æœï¼ˆv3 é”šç‚¹åˆ†æ®µ + æ™ºèƒ½å¯¹é½ï¼‰:\n")
    output_lines.append("-"*60 + "\n")
    
    valid_results = [r for r in final_results if r.get('text', '').strip()]
    
    if not valid_results:
        output_lines.append("âš ï¸ æœªæ£€æµ‹åˆ°æœ‰æ•ˆæ–‡æœ¬å†…å®¹\n")
    else:
        for result in valid_results:
            spk_id = result['spk_id']
            text = result['text'].strip()
            source = result.get('source', '')
            merged = result.get('merged_count', 0)
            
            if text:
                line = f"è¯´è¯äºº {spk_id}: {text}"
                if merged > 1:
                    line += f" [åˆå¹¶{merged}æ®µ]"
                output_lines.append(line + "\n")
    
    output_lines.append("\n" + "="*60 + "\n")
    
    return "".join(output_lines)


if __name__ == "__main__":
    # 1. åŠ è½½æ¨¡å‹
    paraformer_model, sensevoice_model = setup_cascaded_models()
    
    # 2. å¤„ç† recordings ç›®å½•ä¸‹çš„æ‰€æœ‰éŸ³é¢‘æ–‡ä»¶
    recordings_dir = DEFAULT_OUTPUT_DIR
    
    if not os.path.exists(recordings_dir):
        print(f"âŒ é”™è¯¯: ç›®å½• {recordings_dir} ä¸å­˜åœ¨")
    else:
        audio_files = [f for f in os.listdir(recordings_dir) 
                      if f.endswith(('.webm', '.mp3', '.wav', '.m4a', '.flac'))]
        
        if not audio_files:
            print(f"âš ï¸ åœ¨ {recordings_dir} ä¸­æœªæ‰¾åˆ°éŸ³é¢‘æ–‡ä»¶")
        else:
            print(f"\nğŸ“ æ‰¾åˆ° {len(audio_files)} ä¸ªéŸ³é¢‘æ–‡ä»¶ï¼Œå¼€å§‹å¤„ç†...\n")
            
            for idx, audio_file in enumerate(sorted(audio_files), 1):
                audio_path = os.path.join(recordings_dir, audio_file)
                print(f"\n{'='*60}")
                print(f"æ–‡ä»¶ {idx}/{len(audio_files)}: {audio_file}")
                print(f"{'='*60}")
                
                try:
                    final_results = process_audio_cascaded(
                        audio_path, paraformer_model, sensevoice_model
                    )
                    
                    formatted_result = format_cascaded_result(final_results, audio_file)
                    print("\n" + formatted_result)
                    
                    output_file = os.path.join(
                        recordings_dir, 
                        f"{os.path.splitext(audio_file)[0]}_v3_transcription.txt"
                    )
                    with open(output_file, 'w', encoding='utf-8') as f:
                        f.write(formatted_result)
                    print(f"ğŸ’¾ ç»“æœå·²ä¿å­˜åˆ°: {output_file}\n")
                    
                except Exception as e:
                    print(f"âŒ å¤„ç†æ–‡ä»¶ {audio_file} æ—¶å‡ºé”™: {str(e)}")
                    traceback.print_exc()
            
            print(f"\nâœ… æ‰€æœ‰æ–‡ä»¶å¤„ç†å®Œæˆï¼")

"""
çº§è”ç³»ç»Ÿï¼šå…ˆ Paraformer åš Diarizationï¼Œå†ç”¨ SenseVoice è¯†åˆ«æ–‡æœ¬
å®ç°"ç”¨ Paraformer å®šä½å®šäººï¼Œç”¨ SenseVoice ä¿®æ­£å†…å®¹"çš„æ–¹æ¡ˆ
"""

import os
import time
import re
import tempfile
import traceback
import numpy as np
from funasr import AutoModel
from funasr.utils.postprocess_utils import rich_transcription_postprocess

# å°è¯•å¯¼å…¥éŸ³é¢‘å¤„ç†åº“ï¼ˆä¼˜å…ˆä½¿ç”¨ soundfileï¼Œå¦‚æœä¸æ”¯æŒæ ¼å¼åˆ™ä½¿ç”¨ librosaï¼‰
try:
    import soundfile as sf
    USE_SOUNDFILE = True
except ImportError:
    USE_SOUNDFILE = False

try:
    import librosa
    USE_LIBROSA = True
except ImportError:
    USE_LIBROSA = False
    if not USE_SOUNDFILE:
        raise ImportError("éœ€è¦å®‰è£… soundfile æˆ– librosa åº“")

# ================= é…ç½®åŒºåŸŸ =================
DEVICE = "cpu"
THREADS = 4
DEFAULT_OUTPUT_DIR = "/Users/zhengyidi/AutoVoice/recordings"  # é»˜è®¤è¾“å‡ºç›®å½•
# ===========================================

def remove_emoji(text):
    """ç§»é™¤æ–‡æœ¬ä¸­çš„ emojiï¼Œä¿ç•™æ ‡ç‚¹ç¬¦å·å’ŒåŸºæœ¬å­—ç¬¦ï¼ˆåŒ…æ‹¬ä¸­æ–‡ï¼‰"""
    # æ³¨æ„ï¼šç§»é™¤äº† \U000024C2-\U0001F251 èŒƒå›´ï¼Œå› ä¸ºå®ƒåŒ…å«äº†ä¸­æ–‡å­—ç¬¦èŒƒå›´
    emoji_pattern = re.compile(
        "["
        "\U0001F600-\U0001F64F"  # è¡¨æƒ…ç¬¦å·
        "\U0001F300-\U0001F5FF"  # ç¬¦å·å’Œè±¡å½¢æ–‡å­—
        "\U0001F680-\U0001F6FF"  # äº¤é€šå’Œåœ°å›¾ç¬¦å·
        "\U0001F1E0-\U0001F1FF"  # æ——å¸œ
        "\U00002702-\U000027B0"  # å…¶ä»–ç¬¦å·
        "\U0001F900-\U0001F9FF"  # è¡¥å……ç¬¦å·å’Œè±¡å½¢æ–‡å­—
        "\U0001FA00-\U0001FA6F"  # æ‰©å±•ç¬¦å·
        "\U0001FA70-\U0001FAFF"  # æ‰©å±•ç¬¦å·
        "\U00002600-\U000026FF"  # æ‚é¡¹ç¬¦å·
        "\U00002700-\U000027BF"  # è£…é¥°ç¬¦å·
        "]+",
        flags=re.UNICODE
    )
    return emoji_pattern.sub('', text).strip()

def remove_sensevoice_tags(text):
    """
    ç§»é™¤ SenseVoice è¾“å‡ºçš„æ ‡ç­¾ï¼Œåªä¿ç•™çº¯æ–‡æœ¬
    
    ç§»é™¤çš„æ ‡ç­¾æ ¼å¼ï¼š
    - <|en|>, <|zh|>, <|yue|>, <|ja|> ç­‰è¯­è¨€æ ‡ç­¾
    - <|NEUTRAL|>, <|EMO_UNKNOWN|> ç­‰æƒ…ç»ªæ ‡ç­¾
    - <|Speech|>, <|within|> ç­‰å…¶ä»–æ ‡ç­¾
    
    æ³¨æ„ï¼šæ ‡ç­¾æ ¼å¼å¯èƒ½æ˜¯ <|...|> æˆ– < | ... | >ï¼ˆæ ‡ç­¾å†…å¯èƒ½æœ‰ç©ºæ ¼ï¼‰
    """
    if not text:
        return ""
    
    # ç§»é™¤æ‰€æœ‰ <|...|> æ ¼å¼çš„æ ‡ç­¾ï¼ˆåŒ…æ‹¬æ ‡ç­¾å†…å¯èƒ½æœ‰ç©ºæ ¼çš„æƒ…å†µï¼‰
    # åŒ¹é… <|...|> æˆ– < | ... | > ç­‰æ ¼å¼
    tag_pattern = re.compile(r'<\s*\|[^|]*\|\s*>')
    text = tag_pattern.sub('', text)
    
    # æ¸…ç†å¤šä½™çš„ç©ºæ ¼ï¼ˆå¤šä¸ªè¿ç»­ç©ºæ ¼å˜æˆä¸€ä¸ªï¼‰
    text = re.sub(r'\s+', ' ', text)
    
    # æ¸…ç†é¦–å°¾ç©ºæ ¼
    text = text.strip()
    
    return text

def extract_audio_segment(audio_path, start_ms, end_ms, buffer_ms=100):
    """
    æå–éŸ³é¢‘ç‰‡æ®µ
    
    Args:
        audio_path: éŸ³é¢‘æ–‡ä»¶è·¯å¾„
        start_ms: å¼€å§‹æ—¶é—´ï¼ˆæ¯«ç§’ï¼‰
        end_ms: ç»“æŸæ—¶é—´ï¼ˆæ¯«ç§’ï¼‰
        buffer_ms: å‰åç¼“å†²æ—¶é—´ï¼ˆæ¯«ç§’ï¼‰ï¼Œé»˜è®¤100ms
    
    Returns:
        audio_segment: éŸ³é¢‘æ•°æ®ï¼ˆnumpy arrayï¼‰
        sample_rate: é‡‡æ ·ç‡
    """
    # æ·»åŠ å‰åç¼“å†²
    start_ms = max(0, start_ms - buffer_ms)
    end_ms = end_ms + buffer_ms
    
    # å°è¯•ä½¿ç”¨ soundfileï¼ˆé€Ÿåº¦å¿«ï¼Œä½†æ ¼å¼æ”¯æŒæœ‰é™ï¼‰
    if USE_SOUNDFILE:
        try:
            audio_data, sample_rate = sf.read(audio_path)
            # è½¬æ¢ä¸ºé‡‡æ ·ç‚¹ç´¢å¼•
            start_sample = int(start_ms * sample_rate / 1000)
            end_sample = int(end_ms * sample_rate / 1000)
            # ç¡®ä¿ä¸è¶…å‡ºèŒƒå›´
            start_sample = max(0, start_sample)
            end_sample = min(len(audio_data), end_sample)
            # æå–ç‰‡æ®µ
            segment = audio_data[start_sample:end_sample]
            return segment, sample_rate
        except Exception:
            # soundfile ä¸æ”¯æŒè¯¥æ ¼å¼ï¼Œé™çº§ä½¿ç”¨ librosa
            pass
    
    # ä½¿ç”¨ librosaï¼ˆæ”¯æŒæ›´å¤šæ ¼å¼ï¼Œä½†å¯èƒ½è¾ƒæ…¢ï¼‰
    if USE_LIBROSA:
        # librosa ä½¿ç”¨ç§’ä½œä¸ºå•ä½
        start_sec = start_ms / 1000.0
        end_sec = end_ms / 1000.0
        duration = end_sec - start_sec
        
        # è¯»å–æŒ‡å®šæ—¶é—´æ®µçš„éŸ³é¢‘
        audio_data, sample_rate = librosa.load(
            audio_path,
            offset=start_sec,
            duration=duration,
            sr=None  # ä¿æŒåŸå§‹é‡‡æ ·ç‡
        )
        
        return audio_data, sample_rate
    
    raise RuntimeError("æ— æ³•è¯»å–éŸ³é¢‘æ–‡ä»¶ï¼šsoundfile å’Œ librosa éƒ½ä¸å¯ç”¨")

def setup_cascaded_models():
    """
    åˆå§‹åŒ–çº§è”ç³»ç»Ÿæ‰€éœ€çš„æ¨¡å‹
    """
    print("ğŸ”„ æ­£åœ¨åŠ è½½ Paraformer + Cam++ æ¨¡å‹...")
    start_time = time.time()
    
    paraformer_model = AutoModel(
        model="paraformer-zh",
        vad_model="fsmn-vad",
        punc_model="ct-punc",
        spk_model="cam++",
        device=DEVICE,
        ncpu=THREADS,
        disable_update=True
    )
    
    elapsed = time.time() - start_time
    print(f"âœ… Paraformer + Cam++ æ¨¡å‹åŠ è½½å®Œæˆï¼Œè€—æ—¶: {elapsed:.2f}ç§’")
    
    print("ğŸ”„ æ­£åœ¨åŠ è½½ SenseVoice æ¨¡å‹...")
    start_time = time.time()
    
    sensevoice_model = AutoModel(
        model="iic/SenseVoiceSmall",
        trust_remote_code=True,
        vad_model="fsmn-vad",
        vad_kwargs={"max_single_segment_time": 30000},
        punc_model="ct-punc",
        device=DEVICE,
        ncpu=THREADS,
        disable_update=True
    )
    
    elapsed = time.time() - start_time
    print(f"âœ… SenseVoice æ¨¡å‹åŠ è½½å®Œæˆï¼Œè€—æ—¶: {elapsed:.2f}ç§’")
    
    return paraformer_model, sensevoice_model

def process_audio_cascaded(audio_path, paraformer_model, sensevoice_model, log_callback=None, log_detail_callback=None):
    """
    çº§è”å¤„ç†éŸ³é¢‘ï¼šå…ˆ Paraformer åš diarizationï¼Œå†ç”¨ SenseVoice è¯†åˆ«
    
    Args:
        audio_path: éŸ³é¢‘æ–‡ä»¶è·¯å¾„
        paraformer_model: Paraformer + Cam++ æ¨¡å‹
        sensevoice_model: SenseVoice æ¨¡å‹
        log_callback: æ—¥å¿—å›è°ƒå‡½æ•°ï¼ˆå¯é€‰ï¼‰ï¼Œç”¨äº GUI æ˜¾ç¤º
        log_detail_callback: è¯¦ç»†æ—¥å¿—å›è°ƒå‡½æ•°ï¼ˆå¯é€‰ï¼‰ï¼Œç”¨äº GUI æ˜¾ç¤º
    
    Returns:
        final_results: æœ€ç»ˆç»“æœåˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ åŒ…å« spk_id, start, end, text
    """
    def log(msg, level="main"):
        if log_callback:
            log_callback(msg, level)
        else:
            print(f"[{level}] {msg}")
    
    def log_detail(msg, level="info"):
        if log_detail_callback:
            log_detail_callback(msg, level)
        else:
            print(f"[{level}] {msg}")
    
    # === æ­¥éª¤ 1: Paraformer å¤„ç†ï¼ˆè·å–æ—¶é—´æˆ³å’Œè¯´è¯äººIDï¼‰ ===
    log("="*60)
    log("ğŸ”„ æ­¥éª¤ 1/3: ä½¿ç”¨ Paraformer è¿›è¡Œè¯´è¯äººåŒºåˆ†...")
    log("="*60)
    
    start_time = time.time()
    paraformer_res = paraformer_model.generate(
        input=audio_path,
        cache={},
        language="auto",
        use_itn=True,
        batch_size_s=60,
        merge_vad=True,
    )
    
    if not paraformer_res or len(paraformer_res) == 0:
        raise ValueError("Paraformer å¤„ç†å¤±è´¥ï¼šæœªè¿”å›ç»“æœ")
    
    paraformer_result = paraformer_res[0]
    sentence_info = paraformer_result.get('sentence_info', [])
    
    if not sentence_info:
        raise ValueError("Paraformer å¤„ç†å¤±è´¥ï¼šæœªæ£€æµ‹åˆ°å¥å­ä¿¡æ¯")
    
    elapsed = time.time() - start_time
    log(f"âœ… æ£€æµ‹åˆ° {len(sentence_info)} ä¸ªå¥å­ç‰‡æ®µï¼Œè€—æ—¶: {elapsed:.2f}ç§’")
    
    # === æ­¥éª¤ 2: å°†ç‰‡æ®µæŒ‰30ç§’çª—å£åˆ†ç»„ï¼Œåˆå¹¶åç»Ÿä¸€ç”¨ SenseVoice è¯†åˆ« ===
    log("")
    log("="*60)
    log("ğŸ”„ æ­¥éª¤ 2/3: å°†ç‰‡æ®µæŒ‰30ç§’çª—å£åˆ†ç»„ï¼Œåˆå¹¶åç”¨ SenseVoice æ‰¹é‡è¯†åˆ«...")
    log("="*60)
    
    # SenseVoice å†…éƒ¨ä»¥30ç§’ä¸ºæœ€ä¼˜ç‰‡æ®µé•¿åº¦ï¼Œæ‰€ä»¥æˆ‘ä»¬æŒ‰30ç§’çª—å£åˆ†ç»„
    SEGMENT_WINDOW_SEC = 30  # 30ç§’çª—å£
    SEGMENT_WINDOW_MS = SEGMENT_WINDOW_SEC * 1000
    
    # å°† sentence_info æŒ‰30ç§’çª—å£åˆ†ç»„
    window_groups = []
    current_window_start = 0
    current_group = []
    
    for sent_info in sentence_info:
        start_ms = sent_info['start']
        end_ms = sent_info['end']
        
        # å¦‚æœå½“å‰ç‰‡æ®µè¶…å‡ºå½“å‰çª—å£ï¼Œå¼€å§‹æ–°çª—å£
        if start_ms >= current_window_start + SEGMENT_WINDOW_MS:
            if current_group:
                window_groups.append({
                    'window_start': current_window_start,
                    'window_end': current_window_start + SEGMENT_WINDOW_MS,
                    'segments': current_group
                })
            current_window_start = (start_ms // SEGMENT_WINDOW_MS) * SEGMENT_WINDOW_MS
            current_group = []
        
        current_group.append(sent_info)
    
    # æ·»åŠ æœ€åä¸€ç»„
    if current_group:
        window_groups.append({
            'window_start': current_window_start,
            'window_end': current_window_start + SEGMENT_WINDOW_MS,
            'segments': current_group
        })
    
    log(f"ğŸ“Š å°† {len(sentence_info)} ä¸ªç‰‡æ®µåˆ†ç»„ä¸º {len(window_groups)} ä¸ª30ç§’çª—å£")
    for i, group in enumerate(window_groups, 1):
        log(f"  çª—å£ {i}: {len(group['segments'])} ä¸ªç‰‡æ®µï¼Œæ—¶é—´èŒƒå›´: {group['window_start']}ms - {group['window_end']}ms", "sub")
    
    sensevoice_results = []
    total_start_time = time.time()
    
    # æå–å¹¶åˆå¹¶30ç§’çª—å£çš„éŸ³é¢‘
    log(f"å‡†å¤‡æå–å¹¶åˆå¹¶ {len(window_groups)} ä¸ª30ç§’çª—å£çš„éŸ³é¢‘...")
    extract_start_time = time.time()
    
    window_audio_files = []
    window_info_list = []
    
    for window_idx, window_group in enumerate(window_groups):
        window_start_ms = window_group['window_start']
        window_end_ms = window_group['window_end']
        segments = window_group['segments']
        
        try:
            # æå–æ•´ä¸ª30ç§’çª—å£çš„éŸ³é¢‘
            audio_segment, sample_rate = extract_audio_segment(
                audio_path, window_start_ms, window_end_ms
            )
            
            # å¦‚æœéŸ³é¢‘é•¿åº¦ä¸è¶³30ç§’ï¼Œç”¨é™éŸ³å¡«å……ï¼ˆä¿æŒåŸå§‹é•¿åº¦ä¹Ÿå¯ä»¥ï¼‰
            expected_samples = int(SEGMENT_WINDOW_SEC * sample_rate)
            if len(audio_segment) < expected_samples:
                # ç”¨é™éŸ³å¡«å……åˆ°30ç§’
                padding_samples = expected_samples - len(audio_segment)
                if len(audio_segment.shape) == 1:
                    # å•å£°é“
                    padding = np.zeros(padding_samples, dtype=audio_segment.dtype)
                else:
                    # å¤šå£°é“
                    padding = np.zeros((padding_samples, audio_segment.shape[1]), dtype=audio_segment.dtype)
                audio_segment = np.concatenate([audio_segment, padding])
            
            # ä¿å­˜ä¸ºä¸´æ—¶æ–‡ä»¶
            with tempfile.NamedTemporaryFile(suffix='.wav', delete=False) as tmp_file:
                tmp_path = tmp_file.name
                if USE_SOUNDFILE:
                    sf.write(tmp_path, audio_segment, sample_rate)
                elif USE_LIBROSA:
                    import soundfile as sf_write
                    sf_write.write(tmp_path, audio_segment, sample_rate)
                else:
                    raise RuntimeError("æ— æ³•å†™å…¥éŸ³é¢‘æ–‡ä»¶ï¼šsoundfile ä¸å¯ç”¨")
            
            window_audio_files.append(tmp_path)
            window_info_list.append({
                'window_idx': window_idx,
                'window_start': window_start_ms,
                'window_end': window_end_ms,
                'segments': segments  # ä¿å­˜åŸå§‹ç‰‡æ®µä¿¡æ¯ï¼Œç”¨äºåç»­æ˜ å°„
            })
            
        except Exception as e:
            log(f"  âŒ æå–çª—å£ {window_idx+1} æ—¶å‡ºé”™: {str(e)}", "error")
            log_detail(f"æå–çª—å£ {window_idx+1} æ—¶å‡ºé”™: {str(e)}", "error")
            log_detail(traceback.format_exc(), "error")
            # é™çº§ï¼šä½¿ç”¨ Paraformer çš„æ–‡æœ¬
            for seg_info in segments:
                text = seg_info.get('text', '')
                text = remove_emoji(text)
                sensevoice_results.append({
                    'spk_id': seg_info.get('spk', 'unknown'),
                    'start': seg_info['start'],
                    'end': seg_info['end'],
                    'text': text
                })
    
    extract_time = time.time() - extract_start_time
    log(f"âœ… 30ç§’çª—å£éŸ³é¢‘æå–å®Œæˆï¼Œè€—æ—¶: {extract_time:.2f}ç§’")
    
    # æ‰¹é‡å¤„ç† SenseVoice è¯†åˆ«ï¼ˆæ¯æ‰¹å¤„ç†å¤šä¸ª30ç§’çª—å£ï¼‰
    BATCH_SIZE = 8  # æ¯æ‰¹å¤„ç†8ä¸ª30ç§’çª—å£
    log(f"å¼€å§‹æ‰¹é‡è¯†åˆ«ï¼ˆæ¯æ‰¹ {BATCH_SIZE} ä¸ª30ç§’çª—å£ï¼‰...")
    sense_start_time = time.time()
    
    for batch_start in range(0, len(window_audio_files), BATCH_SIZE):
        batch_end = min(batch_start + BATCH_SIZE, len(window_audio_files))
        batch_files = window_audio_files[batch_start:batch_end]
        batch_info = window_info_list[batch_start:batch_end]
        
        log(f"å¤„ç†æ‰¹æ¬¡ {batch_start//BATCH_SIZE + 1}/{(len(window_audio_files) + BATCH_SIZE - 1)//BATCH_SIZE}: çª—å£ {batch_start+1}-{batch_end}")
        
        try:
            # æ‰¹é‡è°ƒç”¨ SenseVoice å¤„ç†30ç§’çª—å£
            batch_sense_res = sensevoice_model.generate(
                input=batch_files,
                cache={},
                language="auto",
                use_itn=True,
            )
            
            # å¤„ç†æ¯ä¸ª30ç§’çª—å£çš„ç»“æœï¼Œæ˜ å°„å›åŸå§‹å°ç‰‡æ®µ
            for i, (window_info, sense_res) in enumerate(zip(batch_info, batch_sense_res)):
                window_idx = window_info['window_idx']
                window_start_ms = window_info['window_start']
                window_end_ms = window_info['window_end']
                segments = window_info['segments']
                
                # æå– SenseVoice çš„æ–‡æœ¬
                window_text = ""
                if sense_res:
                    if isinstance(sense_res, list):
                        if len(sense_res) > 0:
                            result_item = sense_res[0]
                            if isinstance(result_item, dict):
                                window_text = result_item.get('text', '')
                            else:
                                window_text = str(result_item)
                    elif isinstance(sense_res, dict):
                        window_text = sense_res.get('text', '')
                    else:
                        window_text = str(sense_res) if sense_res else ""
                
                # åå¤„ç†ï¼šç§»é™¤æ ‡ç­¾å’Œ emoji
                if window_text and window_text.strip():
                    window_text = remove_sensevoice_tags(window_text)
                    window_text = rich_transcription_postprocess(window_text)
                    window_text = remove_emoji(window_text)
                
                # å°†30ç§’çª—å£çš„æ–‡æœ¬æ˜ å°„å›åŸå§‹å°ç‰‡æ®µ
                # ç­–ç•¥ï¼šå¦‚æœçª—å£å†…åªæœ‰ä¸€ä¸ªç‰‡æ®µï¼Œç›´æ¥ä½¿ç”¨æ•´ä¸ªæ–‡æœ¬
                # å¦‚æœæœ‰å¤šä¸ªç‰‡æ®µï¼ŒæŒ‰æ—¶é—´æ¯”ä¾‹åˆ†é…æ–‡æœ¬ï¼ˆç®€åŒ–å¤„ç†ï¼‰
                if window_text and window_text.strip():
                    if len(segments) == 1:
                        # åªæœ‰ä¸€ä¸ªç‰‡æ®µï¼Œç›´æ¥ä½¿ç”¨æ•´ä¸ªæ–‡æœ¬
                        seg_info = segments[0]
                        text = window_text
                        spk_id = seg_info.get('spk', 'unknown')
                        start_ms = seg_info['start']
                        end_ms = seg_info['end']
                        
                        if text and text.strip():
                            log(f"  çª—å£ {window_idx+1} ç‰‡æ®µ 1 (è¯´è¯äºº {spk_id}): {text[:50]}..." if len(text) > 50 else f"  çª—å£ {window_idx+1} ç‰‡æ®µ 1 (è¯´è¯äºº {spk_id}): {text}", "sub")
                            sensevoice_results.append({
                                'spk_id': spk_id,
                                'start': start_ms,
                                'end': end_ms,
                                'text': text.strip()
                            })
                    else:
                        # å¤šä¸ªç‰‡æ®µï¼šä½¿ç”¨ Paraformer çš„æ–‡æœ¬ï¼ˆå› ä¸ºæ— æ³•å‡†ç¡®åˆ†å‰² SenseVoice çš„æ–‡æœ¬ï¼‰
                        log(f"  çª—å£ {window_idx+1} åŒ…å« {len(segments)} ä¸ªç‰‡æ®µï¼Œä½¿ç”¨ Paraformer æ–‡æœ¬", "sub")
                        for seg_info in segments:
                            text = seg_info.get('text', '')
                            text = remove_emoji(text)
                            if text and text.strip():
                                sensevoice_results.append({
                                    'spk_id': seg_info.get('spk', 'unknown'),
                                    'start': seg_info['start'],
                                    'end': seg_info['end'],
                                    'text': text.strip()
                                })
                else:
                    # SenseVoice è¯†åˆ«å¤±è´¥ï¼Œé™çº§ä½¿ç”¨ Paraformer æ–‡æœ¬
                    log(f"  çª—å£ {window_idx+1} SenseVoice è¯†åˆ«å¤±è´¥ï¼Œä½¿ç”¨ Paraformer æ–‡æœ¬", "warning")
                    for seg_info in segments:
                        text = seg_info.get('text', '')
                        text = remove_emoji(text)
                        if text and text.strip():
                            sensevoice_results.append({
                                'spk_id': seg_info.get('spk', 'unknown'),
                                'start': seg_info['start'],
                                'end': seg_info['end'],
                                'text': text.strip()
                            })
                
        except Exception as e:
            log(f"  âŒ æ‰¹æ¬¡å¤„ç†å‡ºé”™: {str(e)}", "error")
            log_detail(f"æ‰¹æ¬¡å¤„ç†å‡ºé”™: {str(e)}", "error")
            log_detail(traceback.format_exc(), "error")
            # é™çº§å¤„ç†ï¼šé€ä¸ªå¤„ç†è¿™ä¸ªæ‰¹æ¬¡çš„çª—å£
            for window_info in batch_info:
                window_idx = window_info['window_idx']
                segments = window_info['segments']
                tmp_path = window_audio_files[batch_start + batch_info.index(window_info)]
                
                try:
                    single_res = sensevoice_model.generate(
                        input=tmp_path,
                        cache={},
                        language="auto",
                        use_itn=True,
                    )
                    
                    window_text = ""
                    if single_res:
                        if isinstance(single_res, list):
                            if len(single_res) > 0:
                                result_item = single_res[0]
                                if isinstance(result_item, dict):
                                    window_text = result_item.get('text', '')
                                else:
                                    window_text = str(result_item)
                        elif isinstance(single_res, dict):
                            window_text = single_res.get('text', '')
                        else:
                            window_text = str(single_res) if single_res else ""
                    
                    if window_text and window_text.strip():
                        window_text = remove_sensevoice_tags(window_text)
                        window_text = rich_transcription_postprocess(window_text)
                        window_text = remove_emoji(window_text)
                        
                        # å¦‚æœåªæœ‰ä¸€ä¸ªç‰‡æ®µï¼Œç›´æ¥ä½¿ç”¨
                        if len(segments) == 1 and window_text:
                            seg_info = segments[0]
                            sensevoice_results.append({
                                'spk_id': seg_info.get('spk', 'unknown'),
                                'start': seg_info['start'],
                                'end': seg_info['end'],
                                'text': window_text.strip()
                            })
                        else:
                            # å¤šä¸ªç‰‡æ®µï¼Œä½¿ç”¨ Paraformer æ–‡æœ¬
                            for seg_info in segments:
                                text = seg_info.get('text', '')
                                text = remove_emoji(text)
                                if text and text.strip():
                                    sensevoice_results.append({
                                        'spk_id': seg_info.get('spk', 'unknown'),
                                        'start': seg_info['start'],
                                        'end': seg_info['end'],
                                        'text': text.strip()
                                    })
                    else:
                        # ä½¿ç”¨ Paraformer æ–‡æœ¬
                        for seg_info in segments:
                            text = seg_info.get('text', '')
                            text = remove_emoji(text)
                            if text and text.strip():
                                sensevoice_results.append({
                                    'spk_id': seg_info.get('spk', 'unknown'),
                                    'start': seg_info['start'],
                                    'end': seg_info['end'],
                                    'text': text.strip()
                                })
                except Exception as e2:
                    # æœ€ç»ˆé™çº§ï¼šä½¿ç”¨ Paraformer æ–‡æœ¬
                    for seg_info in segments:
                        text = seg_info.get('text', '')
                        text = remove_emoji(text)
                        if text and text.strip():
                            sensevoice_results.append({
                                'spk_id': seg_info.get('spk', 'unknown'),
                                'start': seg_info['start'],
                                'end': seg_info['end'],
                                'text': text.strip()
                            })
        
        finally:
            # æ¸…ç†è¿™ä¸ªæ‰¹æ¬¡çš„ä¸´æ—¶æ–‡ä»¶
            for tmp_path in batch_files:
                if os.path.exists(tmp_path):
                    try:
                        os.unlink(tmp_path)
                    except:
                        pass
    
    sense_time = time.time() - sense_start_time
    log(f"âœ… SenseVoice æ‰¹é‡è¯†åˆ«å®Œæˆï¼Œè€—æ—¶: {sense_time:.2f}ç§’")
    
    total_elapsed = time.time() - total_start_time
    log("")
    log(f"âœ… æ‰€æœ‰ç‰‡æ®µå¤„ç†å®Œæˆï¼Œæ€»è€—æ—¶: {total_elapsed:.2f}ç§’")
    
    return sensevoice_results

def format_cascaded_result(final_results, audio_file):
    """
    æ ¼å¼åŒ–çº§è”ç³»ç»Ÿçš„è¾“å‡ºç»“æœ
    """
    output_lines = []
    output_lines.append(f"éŸ³é¢‘æ–‡ä»¶: {os.path.basename(audio_file)}\n")
    output_lines.append("="*60 + "\n")
    output_lines.append("ğŸ“¢ è¯´è¯äººåŒºåˆ†ç»“æœï¼ˆä½¿ç”¨ SenseVoice è¯†åˆ«ï¼‰:\n")
    output_lines.append("-"*60 + "\n")
    
    # è¿‡æ»¤æ‰ç©ºæ–‡æœ¬çš„ç»“æœ
    valid_results = [r for r in final_results if r.get('text', '').strip()]
    
    if not valid_results:
        output_lines.append("âš ï¸ æœªæ£€æµ‹åˆ°æœ‰æ•ˆæ–‡æœ¬å†…å®¹\n")
    else:
        for result in valid_results:
            spk_id = result['spk_id']
            text = result['text'].strip()
            
            # åªè¾“å‡ºéç©ºæ–‡æœ¬
            if text:
                output_lines.append(f"è¯´è¯äºº {spk_id}: {text}\n")
    
    output_lines.append("\n" + "="*60 + "\n")
    
    return "".join(output_lines)

if __name__ == "__main__":
    # 1. åŠ è½½æ¨¡å‹
    paraformer_model, sensevoice_model = setup_cascaded_models()
    
    # 2. å¤„ç† recordings ç›®å½•ä¸‹çš„æ‰€æœ‰éŸ³é¢‘æ–‡ä»¶
    recordings_dir = DEFAULT_OUTPUT_DIR
    
    if not os.path.exists(recordings_dir):
        print(f"âŒ é”™è¯¯: ç›®å½• {recordings_dir} ä¸å­˜åœ¨")
    else:
        # è·å–æ‰€æœ‰éŸ³é¢‘æ–‡ä»¶
        audio_files = [f for f in os.listdir(recordings_dir) 
                      if f.endswith(('.webm', '.mp3', '.wav', '.m4a', '.flac'))]
        
        if not audio_files:
            print(f"âš ï¸ åœ¨ {recordings_dir} ä¸­æœªæ‰¾åˆ°éŸ³é¢‘æ–‡ä»¶")
        else:
            print(f"\nğŸ“ æ‰¾åˆ° {len(audio_files)} ä¸ªéŸ³é¢‘æ–‡ä»¶ï¼Œå¼€å§‹å¤„ç†...\n")
            
            for idx, audio_file in enumerate(sorted(audio_files), 1):
                audio_path = os.path.join(recordings_dir, audio_file)
                print(f"\n{'='*60}")
                print(f"æ–‡ä»¶ {idx}/{len(audio_files)}: {audio_file}")
                print(f"{'='*60}")
                
                try:
                    # çº§è”å¤„ç†
                    final_results = process_audio_cascaded(
                        audio_path, paraformer_model, sensevoice_model
                    )
                    
                    # æ ¼å¼åŒ–è¾“å‡º
                    formatted_result = format_cascaded_result(final_results, audio_file)
                    
                    print("\n" + formatted_result)
                    
                    # ä¿å­˜ç»“æœåˆ°æ–‡ä»¶
                    output_file = os.path.join(
                        recordings_dir, 
                        f"{os.path.splitext(audio_file)[0]}_cascaded_transcription.txt"
                    )
                    with open(output_file, 'w', encoding='utf-8') as f:
                        f.write(formatted_result)
                    print(f"ğŸ’¾ ç»“æœå·²ä¿å­˜åˆ°: {output_file}\n")
                    
                except Exception as e:
                    print(f"âŒ å¤„ç†æ–‡ä»¶ {audio_file} æ—¶å‡ºé”™: {str(e)}")
                    import traceback
                    traceback.print_exc()
            
            print(f"\nâœ… æ‰€æœ‰æ–‡ä»¶å¤„ç†å®Œæˆï¼")

